# Machine Learning Notes
Preparing for the exam

## Gradient descent
### Definitions
- Gradient descent computes the direction of steepest descent.
- Accuracy is a bad loss function in gradient descent, becasue gradient descent makes the gradient zero almost everywhere.
### VU material Week 6: 
- [VU video](https://youtu.be/3K4pNmQbGx8?t=2550)


***
## Principal Component Analysis
### Definitions
Principal Component Analysis, or PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.
- PCA provides a normalisation that accounts for correlations between
features.
- PCA finds a change of basis for the data.
- The first principal component is the direction in which the variance is
highest.
### VU material Week 11: 
- [VU video1](https://youtu.be/L2mJ4o7F434) 
- [VU video2](https://www.youtube.com/watch?v=H4c4qpHdGq8&feature=youtu.be)
- [Everything you did and didn't know about PCA](http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/)

### Other videos:
- [article: step-by-step-explanation-of-principal-component-analysis](https://towardsdatascience.com/a-step-by-step-explanation-of-principal-component-analysis-b836fb9c97e2)
- [video: Principal Component Analysis (PCA)](https://www.youtube.com/watch?v=g-Hb26agBFg)

***

## CycleGANs
## Definitions
### VU material Week 10: 
- [VU video1](https://www.youtube.com/watch?v=6N4zIx0ATME&feature=youtu.be)

### Other videos:
- [video: Generative Adversarial Networks (GANs) - How and Why They Work](https://youtu.be/ZRgwcMqxhPw)
- [video: Turning Fortnite into PUBG with Deep Learning (CycleGANs)](https://youtu.be/xkLtgwWxrec)



***
## Generative VS Discriminative Models
- [article: “is this animal a lion or an elephant?”](https://medium.com/@mlengineer/generative-and-discriminative-models-af5637a66a3)
